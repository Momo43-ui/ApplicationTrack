"""
Service de chatbot intelligent pour ApplicationTrack
Utilise Gemini pour analyser et conseiller l'utilisateur sur ses candidatures
"""

import os
import requests
from typing import Dict, List, Optional

class ChatBotService:
    def __init__(self):
        self.gemini_key = os.getenv('GEMINI_API_KEY')
        
    def generate_response(
        self, 
        user_message: str,
        candidatures: Optional[List[Dict]] = None,
        user_info: Optional[Dict] = None
    ) -> Dict:
        """
        GÃ©nÃ¨re une rÃ©ponse intelligente basÃ©e sur le message et le contexte
        
        Args:
            user_message: Message de l'utilisateur
            candidatures: Liste des candidatures pour contexte
            user_info: Informations sur l'utilisateur
            
        Returns:
            Dict avec la rÃ©ponse et mÃ©tadonnÃ©es
        """
        if not self.gemini_key:
            return self._generate_fallback_response(user_message, candidatures)
        
        prompt = self._build_prompt(user_message, candidatures, user_info)
        
        try:
            return self._generate_with_gemini(prompt)
        except Exception as e:
            print(f"[CHATBOT] Erreur Gemini: {e}")
            return self._generate_fallback_response(user_message, candidatures)
    
    def _build_prompt(
        self, 
        user_message: str, 
        candidatures: Optional[List[Dict]], 
        user_info: Optional[Dict]
    ) -> str:
        """Construit le prompt avec contexte"""
        
        # DÃ©terminer si l'utilisateur demande vraiment des infos sur les candidatures
        message_lower = user_message.lower()
        needs_candidatures = any(word in message_lower for word in [
            'candidature', 'postule', 'entreprise', 'statut', 'combien', 
            'statistique', 'analyse', 'entretien', 'refus', 'acceptÃ©'
        ])
        
        # Analyser les candidatures seulement si nÃ©cessaire
        stats = {}
        if needs_candidatures and candidatures:
            stats = self._analyze_candidatures(candidatures)
        
        prompt = f"""Tu es un assistant virtuel pour le suivi de candidatures. RÃ©ponds de maniÃ¨re CONCISE et PERTINENTE.

**MESSAGE :** "{user_message}"
"""

        # Ajouter le contexte seulement si pertinent
        if needs_candidatures and stats:
            prompt += f"""
**STATISTIQUES :**
- Total : {stats.get('total', 0)} | En attente : {stats.get('en_attente', 0)} | Entretiens : {stats.get('entretiens', 0)} | Refus : {stats.get('refuses', 0)} | AcceptÃ©es : {stats.get('acceptees', 0)}
"""
            if candidatures and len(candidatures) > 0:
                prompt += "\n**DERNIÃˆRES CANDIDATURES :**\n"
                for c in candidatures[:3]:  # Seulement 3
                    prompt += f"- {c.get('entreprise', 'N/A')} ({c.get('etat', 'N/A')})\n"
        
        prompt += """
**INSTRUCTIONS :**
1. Si c'est une salutation simple ("bonjour", "comment vas-tu"), rÃ©ponds briÃ¨vement et amicalement
2. Si on te demande des stats, fournis-les de maniÃ¨re claire
3. Si on demande des conseils, sois prÃ©cis et actionnable
4. Utilise des emojis mais reste professionnel
5. RESTE BREF : Maximum 150 mots pour les questions simples, 250 pour les analyses

RÃ©ponds maintenant de maniÃ¨re CONCISE et COMPLÃˆTE :"""
        
        return prompt
    
    def _analyze_candidatures(self, candidatures: List[Dict]) -> Dict:
        """Analyse rapide des candidatures pour les stats"""
        stats = {
            'total': len(candidatures),
            'en_attente': 0,
            'entretiens': 0,
            'refuses': 0,
            'acceptees': 0
        }
        
        for c in candidatures:
            etat = c.get('etat', '')
            if etat in ['en_attente', 'candidature_envoyee']:
                stats['en_attente'] += 1
            elif etat == 'entretien_passe':
                stats['entretiens'] += 1
            elif etat == 'refuse':
                stats['refuses'] += 1
            elif etat == 'accepte':
                stats['acceptees'] += 1
        
        return stats
    
    def _generate_with_gemini(self, prompt: str) -> Dict:
        """GÃ©nÃ¨re avec Gemini"""
        try:
            response = requests.post(
                f'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={self.gemini_key}',
                headers={'Content-Type': 'application/json'},
                json={
                    'contents': [{
                        'parts': [{'text': prompt}]
                    }],
                    'generationConfig': {
                        'temperature': 0.7,
                        'maxOutputTokens': 800,  # RÃ©duit pour rÃ©ponses plus courtes
                        'topP': 0.95,
                        'topK': 40
                    }
                },
                timeout=30
            )
            
            if not response.ok:
                print(f"[CHATBOT] Erreur API: {response.status_code} - {response.text}")
                raise Exception(f"Erreur API Gemini: {response.status_code}")
            
            data = response.json()
            
            if 'candidates' not in data or len(data['candidates']) == 0:
                print(f"[CHATBOT] Pas de candidats dans la rÃ©ponse: {data}")
                raise Exception("RÃ©ponse Gemini vide")
            
            response_text = data['candidates'][0]['content']['parts'][0]['text']
            
            print(f"[CHATBOT] RÃ©ponse gÃ©nÃ©rÃ©e: {len(response_text)} caractÃ¨res")
            
            return {
                'success': True,
                'response': response_text,
                'provider': 'Gemini 2.5 Flash'
            }
        except requests.exceptions.RequestException as e:
            print(f"[CHATBOT] Erreur rÃ©seau: {e}")
            raise Exception(f"Erreur de connexion Ã  l'API: {str(e)}")
        except Exception as e:
            print(f"[CHATBOT] Erreur: {e}")
            raise e
    
    def _generate_fallback_response(self, user_message: str, candidatures: Optional[List[Dict]]) -> Dict:
        """RÃ©ponse de secours si Gemini ne fonctionne pas"""
        
        message_lower = user_message.lower()
        stats = self._analyze_candidatures(candidatures) if candidatures else {}
        
        # RÃ©ponses simples basÃ©es sur des mots-clÃ©s
        if any(word in message_lower for word in ['combien', 'nombre', 'statistique', 'total']):
            response = f"""ğŸ“Š **Voici tes statistiques :**

â€¢ Total de candidatures : {stats.get('total', 0)}
â€¢ En attente : {stats.get('en_attente', 0)}
â€¢ Entretiens passÃ©s : {stats.get('entretiens', 0)}
â€¢ Refus : {stats.get('refuses', 0)}
â€¢ AcceptÃ©es : {stats.get('acceptees', 0)}

Continue comme Ã§a ! ğŸ’ª"""
        
        elif any(word in message_lower for word in ['conseil', 'aide', 'comment', 'que faire']):
            response = """ğŸ’¡ **Quelques conseils gÃ©nÃ©raux :**

â€¢ Relance les entreprises 1-2 semaines aprÃ¨s candidature
â€¢ Personnalise chaque lettre de motivation
â€¢ PrÃ©pare des questions pour les entretiens
â€¢ Note tes impressions aprÃ¨s chaque contact
â€¢ Reste motivÃ©(e), la recherche prend du temps !

N'hÃ©site pas Ã  demander plus de dÃ©tails ! ğŸ˜Š"""
        
        elif any(word in message_lower for word in ['relance', 'email', 'contacter']):
            response = """âœ‰ï¸ **ModÃ¨le d'email de relance :**

Objet : Suivi de ma candidature - [Poste]

Bonjour,

Je me permets de revenir vers vous concernant ma candidature pour le poste de [Poste] envoyÃ©e le [Date].

Toujours trÃ¨s intÃ©ressÃ©(e) par cette opportunitÃ©, je reste Ã  votre disposition pour Ã©changer.

Cordialement,
[Ton nom]

Simple et efficace ! ğŸ‘"""
        
        else:
            response = f"""Je suis ton assistant ApplicationTrack ! ğŸ¤–

Je peux t'aider Ã  :
â€¢ ğŸ“Š Analyser tes {stats.get('total', 0)} candidatures
â€¢ ğŸ’¡ Te donner des conseils personnalisÃ©s
â€¢ âœ‰ï¸ RÃ©diger des emails de relance
â€¢ ğŸ¯ PrÃ©parer tes entretiens

Pose-moi une question plus prÃ©cise ! ğŸ˜Š"""
        
        return {
            'success': True,
            'response': response,
            'provider': 'RÃ©ponse automatique'
        }
